import os
import re
from typing import Dict, List

import openai
import numpy as np
import encoding
from sentence_transformers import util
from lexrank import degree_centrality_scores


SENTENCE_TRANSFORMER_MODEL = os.getenv(
    "SENTENCE_TRANSFORMER_MODEL", "distiluse-base-multilingual-cased-v2"
)
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
GPT_PROMT = (
    "Write: 'Title:' and then add the most descriptive title "
    "for the set of text below."
    "After the title add '\nSummary:' and then add the most "
    "descriptive summary for the set of texts, "
    "the summary must contain at most 120 words."
    "\nHere you have the set of texts:\n"
)


def apply_summarization_openai(
    texts: List[str],
    api_key=OPENAI_KEY,
    prompt=GPT_PROMT,
    rand=False,
    n_texts=50,
    threshold=0.1,
):
    """
    Inputs:
            texts, List: list of texts to summarize
            api_key, str: the openai api key
            prompt, str: the prompt for summaries AND titles
    Output, Dict: A dict with 2 fields -> title and summary
    """
    openai.api_key = api_key

    prompt_title = "Provide the most descriptive title for the following text corpus"
    prompt_summary = (
        "Provide the most descriptive summary for the following text corpus"
    )

    if rand:
        texts = np.random.choice(texts, size=50, replace=False)
    else:
        texts = lex_rank_top_sentences(texts, n=n_texts, threshold=threshold)

    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt + ".\n ".join(texts)}],
    )

    content = completion["choices"][0]["message"]["content"]

    if preprocess_gpt_answer(content) == -1:
        title = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt_title + ".\n ".join(texts)}],
        )["choices"][0]["message"]["content"]
        summary = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt_summary + ".\n ".join(texts)}],
        )["choices"][0]["message"]["content"]

        return {"title": title, "summary": summary}

    gpt_answers = process_gpt_answer(content)

    return gpt_answers


def get_title(text: str) -> str:
    "Extracts the title generated by the AI model"
    index = text.find("Title:")
    start = index + len("Title:")
    if index == -1:
        raise Exception("Bad processing from gpt answer, missing Title")

    subtext = text[start:]
    end = subtext.find("\n")
    return subtext[:end]


def get_summary(text: str) -> str:
    "Extracts the summary generated by the AI model"
    index = text.find("Summary:")
    start = index + len("Summary:")
    if index == -1:
        raise Exception("Bad processing from gpt answer, missing Summary")
    subtext = text[start:]
    return subtext


def preprocess_gpt_answer(text: str) -> Dict:
    "preprocess prompt for gpt to avoid errors"
    if len(re.findall(r"title", text.lower())) > 1:
        return -1
    if len(re.findall(r"summary", text.lower())) > 1:
        return -1
    if len(re.findall(r"title", text.lower())) == 0:
        return -1
    if len(re.findall(r"summary", text.lower())) == 0:
        return -1
    return None


def process_gpt_answer(text: str) -> Dict:
    return {"title": get_title(text), "summary": get_summary(text)}


def lex_rank_top_sentences(sentences: List[str], n: int, threshold=None) -> List[str]:
    """
    Objective: Get best n best sentences through lexrank alogrithm

    Inputs:
        - sentences, list: the list of sentences to extract
        - embeddings, list: the list of embeddings
        - n, int: the number of top sentences to find out
        - threshold, float: between 0 and 1 for the lexRank
    Outputs:
        - top_sentences, list: the list of top n sentences
    """

    model = encoding.load_st(SENTENCE_TRANSFORMER_MODEL, "mps")
    embeddings = model.encode(sentences, show_progress_bar=True)

    cosine_scores = util.cos_sim(embeddings, embeddings)
    centrality_scores = degree_centrality_scores(cosine_scores, threshold=threshold)

    top_sentences = np.array(sentences)[np.argsort(centrality_scores)[::-1][:n]]

    return top_sentences
